{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaper for car listings from auto.bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change for amount of pages to scrape\n",
    "pages = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6532 existing listings.\n",
      "Found 19 listings on page 1\n",
      "✅ Scraped: Mercedes-Benz S 550 Mercedes S550 AMG Бяла Перла, Headup, Distronic\n",
      "✅ Scraped: BMW 530 3.0D M57 * ОБДУХВАНЕ* * КОЖА* * ШИБЕДАХ* * ПОДГРЕВ\n",
      "✅ Scraped: Audi Tt 2.0 TFSI DSG 270кс\n",
      "✅ Scraped: VW Golf\n",
      "✅ Scraped: Audi A4\n",
      "✅ Scraped: Skoda Octavia vrs\n",
      "✅ Scraped: BMW 330 Xdrive E90\n",
      "✅ Scraped: VW Golf\n",
      "✅ Scraped: Audi S5 3.0 TFSI Quattro / Technik / Bang & Olufsen / PANO\n",
      "✅ Scraped: Toyota Auris\n",
      "✅ Scraped: Mercedes-Benz C 180 ELEGANCE\n",
      "✅ Scraped: Audi A4\n",
      "✅ Scraped: BMW X5\n",
      "✅ Scraped: Renault Zoe R110 52kWh\n",
      "✅ Scraped: Audi A6 3.0BiTDi/НОЩНО ВИЖДАНЕ/ПЕЧКА/KEYLESS/HEADUP/360CAM\n",
      "✅ Scraped: Opel Astra\n",
      "✅ Scraped: Audi A3 8l\n",
      "✅ Scraped: VW Passat 2, 0TDI-170k.c/4x4/DSG/LED/NAVI/КАМЕРА/ТОП!!!\n",
      "✅ Scraped: Peugeot 308 1, 6i-150k.c/111000kм/АВТОМАТИК/НАВИГАЦИЯ/КОЖА/ТОП\n",
      "✅ Done! Total listings: 7326 saved to auto_bg_cars.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "base_url = \"https://www.auto.bg/obiavi/avtomobili-dzhipove\"\n",
    "output_file = \"auto_bg_cars.csv\"\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    df_existing = pd.read_csv(output_file)\n",
    "    existing_ids = set(df_existing[\"Listing_ID\"].astype(str))\n",
    "    print(f\"Loaded {len(existing_ids)} existing listings.\")\n",
    "else:\n",
    "    df_existing = pd.DataFrame()\n",
    "    existing_ids = set()\n",
    "    print(\"No existing CSV found, starting fresh.\")\n",
    "\n",
    "cars = []\n",
    "\n",
    "\n",
    "for page in range(1, pages): \n",
    "    url = f\"{base_url}?page={page}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    listings = soup.find_all(\"div\", class_=\"resultItem\")\n",
    "    print(f\"Found {len(listings)} listings on page {page}\")\n",
    "\n",
    "    for item in listings:\n",
    "        try:\n",
    "            title_tag = item.find(\"div\", class_=\"link\")\n",
    "            price_tag = item.find(\"div\", class_=\"price\")\n",
    "            href_tag = item.find(\"a\", href=True)\n",
    "\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"N/A\"\n",
    "            price = price_tag.get_text(strip=True) if price_tag else \"N/A\"\n",
    "\n",
    "            listing_id = None\n",
    "            if href_tag:\n",
    "                href = href_tag[\"href\"]\n",
    "                if not href.startswith(\"http\"):\n",
    "                    href = \"https://www.auto.bg\" + href\n",
    "                details_url = href\n",
    "\n",
    "                match = re.search(r\"/obiava/(\\d+)/\", href)\n",
    "                if match:\n",
    "                    listing_id = match.group(1)\n",
    "            if listing_id and listing_id in existing_ids:\n",
    "                print(f\"⏭ Skipping existing listing {listing_id}\")\n",
    "                continue\n",
    "\n",
    "            spec_dict = {}\n",
    "            if details_url:\n",
    "                detail_res = requests.get(details_url, headers=headers)\n",
    "                detail_soup = BeautifulSoup(detail_res.text, \"html.parser\")\n",
    "                table = detail_soup.find(\"table\", class_=\"dowble\")\n",
    "\n",
    "                if table:\n",
    "                    rows = table.find_all(\"tr\")\n",
    "                    for row in rows:\n",
    "                        children = row.find_all([\"th\", \"td\"])\n",
    "                        for i in range(0, len(children), 2):\n",
    "                            key_tag = children[i]\n",
    "                            value_tag = children[i + 1] if i + 1 < len(children) else None\n",
    "                            key = key_tag.get_text(strip=True) if key_tag else f\"Unknown{i}\"\n",
    "                            value = value_tag.get_text(strip=True) if value_tag else \"\"\n",
    "                            spec_dict[key] = value\n",
    "\n",
    "            car_data = {\n",
    "                \"Listing_ID\": listing_id if listing_id else \"N/A\",\n",
    "                \"Title\": title,\n",
    "                \"Price\": price,\n",
    "                \"URL\": details_url\n",
    "            }\n",
    "            car_data.update(spec_dict)\n",
    "            cars.append(car_data)\n",
    "\n",
    "            print(f\"Scraped: {title}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        time.sleep(1)  \n",
    "\n",
    "if cars:\n",
    "    df_new = pd.DataFrame(cars)\n",
    "    if not df_existing.empty:\n",
    "        df_final = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df_final = df_new\n",
    "\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    print(f\"Total listings: {len(df_final)} saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No new listings found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
